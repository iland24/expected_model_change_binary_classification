{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96837f1e-90de-4c2c-93fa-a0b5d03a3fdc",
   "metadata": {
    "id": "71356a8e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import csv\n",
    "import emc\n",
    "import logging \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "\n",
    "from sklearn import preprocessing \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "from matplotlib.ticker import StrMethodFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5059954e-d956-4a5c-a638-a3877c2e59f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('healthcare-dataset-stroke-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65af547-3215-4b00-908c-0ddab1ed94dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a068a225-599c-448d-94f9-d871a616820c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print label counts\n",
    "df['stroke'].value_counts()\n",
    "\n",
    "# Data label is imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386f1a12-b1c4-4483-844e-a6ad5ca9d7d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fill in missing BMI data; use BMI means of each age quantile\n",
    "q1 = df['age'].quantile(0.25)\n",
    "q2 = df['age'].median()\n",
    "q3 = df['age'].quantile(0.75)\n",
    "\n",
    "q1_bmi = round(df[df['age']<=q1]['bmi'].mean(),1)\n",
    "q2_bmi = round(df[(df['age']>q1)&(df['age']<=q2)]['bmi'].mean(),1)\n",
    "q3_bmi = round(df[(df['age']>q2)&(df['age']<=q3)]['bmi'].mean(),1)\n",
    "q4_bmi = round(df[df['age']>q3]['bmi'].mean(),1)\n",
    "\n",
    "q1_bool_mask_sr = df[df['age']<=q1]['bmi'].isna()\n",
    "q1_idx = q1_bool_mask_sr[q1_bool_mask_sr].index\n",
    "df.loc[q1_idx,'bmi']=q1_bmi\n",
    "\n",
    "q2_bool_mask_sr = df[(df['age']>q1)&(df['age']<=q2)]['bmi'].isna()\n",
    "q2_idx = q2_bool_mask_sr[q2_bool_mask_sr].index\n",
    "df.loc[q2_idx,'bmi']=q2_bmi\n",
    "\n",
    "q3_bool_mask_sr = df[(df['age']>q2)&(df['age']<=q3)]['bmi'].isna()\n",
    "q3_idx = q3_bool_mask_sr[q3_bool_mask_sr].index\n",
    "df.loc[q3_idx,'bmi'] = q3_bmi\n",
    "\n",
    "q4_bool_mask_sr = df[df['age']>q3]['bmi'].isna()\n",
    "q4_idx = q4_bool_mask_sr[q4_bool_mask_sr].index\n",
    "df.loc[q4_idx,'bmi'] = q4_bmi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffebb7d0-ae7f-483e-b85d-09c1a071e7bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Categorical data\n",
    "\n",
    "gender, ever_married, Residence_type => binary\n",
    "\n",
    "work_type => one-hot (Nominal)\n",
    "\n",
    "smoking_status => integer (Ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b56b344-8eda-40e4-93d5-def7d3022cc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop single row with \"Other\" gender value\n",
    "df.drop(df[df['gender']=='Other'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d51e2b-b349-472c-a8d2-8bf99e3fb45b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encode \"work_type\" column into one-hot\n",
    "wt_category = pd.Categorical(df['work_type'], categories=['Private','Self-employed','Govt_job','children','Never_worked'])\n",
    "\n",
    "# returns one-hot encoded df\n",
    "one_hot_encoded = pd.get_dummies(wt_category).astype(int)\n",
    "\n",
    "# Drop original work_type col\n",
    "no_wt_df = df.drop('work_type', axis=1)\n",
    "\n",
    "# Concatenate the one-hot encoded DataFrame with the original DataFrame\n",
    "numerical_df = pd.concat([no_wt_df.reset_index(drop=True), one_hot_encoded.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Put stroke label column at the last columns\n",
    "numerical_df = numerical_df[[c for c in numerical_df if c != 'stroke'] + [c for c in numerical_df if c == 'stroke']]\n",
    "\n",
    "# Convert binary labeled columns into 0/1\n",
    "numerical_df['gender'] = pd.factorize(numerical_df['gender'])[0]\n",
    "numerical_df['ever_married'] = pd.factorize(numerical_df['ever_married'])[0]\n",
    "numerical_df['Residence_type'] = pd.factorize(numerical_df['Residence_type'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0900b5aa-d202-45be-9316-133a22077e67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert smoking status to int\n",
    "smoke_encoder = preprocessing.OrdinalEncoder(categories=[['never smoked','Unknown','formerly smoked','smokes']])\n",
    "\n",
    "# Fit and transform the ordinal data\n",
    "num_smoke_data = smoke_encoder.fit_transform(numerical_df['smoking_status'].values.reshape(-1,1))\n",
    "\n",
    "numerical_df['smoking_status']=num_smoke_data.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6844e68-7bf0-44da-9af3-9bdabd9c76d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numerical_df['age'] = numerical_df['age'].astype(int)\n",
    "numerical_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced5396f-5db1-45b2-9430-5bea9494b4e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get label out before normalization\n",
    "is_stroke = numerical_df['stroke'].values\n",
    "numerical_df.drop(columns=['stroke'],inplace=True)\n",
    "\n",
    "# Feature Normalization\n",
    "numerical_df['bmi'] =  np.log(numerical_df['bmi'])\n",
    "numerical_df['avg_glucose_level'] =  np.log(numerical_df['avg_glucose_level'])\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(numerical_df)\n",
    "medical_data = scaler.transform(numerical_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ede223f-b6ec-4f0c-b337-13cf325879f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract id column as a list\n",
    "sample_ids = df['id'].to_numpy()\n",
    "\n",
    "# Drop id column\n",
    "df.drop(columns=['id'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1213bb93-07b6-45f4-84cf-c81c2118df34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(medical_data.shape)\n",
    "print(is_stroke.shape)\n",
    "print(len(sample_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9083d0",
   "metadata": {
    "id": "5f9083d0"
   },
   "source": [
    "## Splitting Imbalanced Data \n",
    "Our data is heavily imbalanced and it is important to balance the major and minor labels. Therefore, we do random oversampling of the minor class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa28a5c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1683271137131,
     "user": {
      "displayName": "Daniel Lee",
      "userId": "05387762087311196943"
     },
     "user_tz": -540
    },
    "id": "3fa28a5c",
    "outputId": "2a3b4daf-ab3e-4602-e7f0-3d9bcc22b20f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test out the oversample/split function\n",
    "train_x, train_y, test_x, test_y, test_ids, train_ids = \\\n",
    "    emc.train_test_split_oversample(medical_data, \n",
    "                                    is_stroke, \n",
    "                                    sample_ids=sample_ids, \n",
    "                                    oversample_type='ros', \n",
    "                                    split_ratio=0.7, \n",
    "                                    oversample_size=0.4,\n",
    "                                    seed=0)\n",
    "\n",
    "print(\"Number of 1 label samples in:\")\n",
    "print(\"Train Set = \", sum(train_y == 1))\n",
    "print(\"Test Set = \", sum(test_y == 1))\n",
    "\n",
    "print(\"Number of 0 label samples in:\")\n",
    "print(\"Train Set = \", sum(train_y == 0))\n",
    "print(\"Test Set = \", sum(test_y == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54dc8c1-e946-40f6-a98f-6b5298649c0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create small dataset for debugging\n",
    "\n",
    "# set number of major&minor labeled samples to be included in small dataset\n",
    "n_samples = 80\n",
    "\n",
    "# identify minor label\n",
    "minor_label = emc.get_minor_label(is_stroke)\n",
    "# get each label indices and slice into small number\n",
    "minor_label_idx_arr = np.where(is_stroke==minor_label)[0]\n",
    "minor_label_idx_arr = np.random.permutation(minor_label_idx_arr)[:n_samples]\n",
    "major_label_idx_arr = np.where(is_stroke!=minor_label)[0]\n",
    "major_label_idx_arr = np.random.permutation(major_label_idx_arr)[:n_samples]\n",
    "\n",
    "# concat both labels\n",
    "small_data = np.concatenate([medical_data[minor_label_idx_arr], medical_data[major_label_idx_arr]])\n",
    "small_label = np.concatenate([is_stroke[minor_label_idx_arr], is_stroke[major_label_idx_arr]])\n",
    "small_sample_ids = np.concatenate([sample_ids[minor_label_idx_arr], sample_ids[major_label_idx_arr]])\n",
    "\n",
    "# shuffle \n",
    "suffled_idx = np.random.permutation(len(small_data))\n",
    "small_data = small_data[suffled_idx]\n",
    "small_label = small_label[suffled_idx]\n",
    "small_sample_ids = small_sample_ids[suffled_idx]\n",
    "\n",
    "print('small_data shape:',small_data.shape)\n",
    "print('small_label shape:',small_label.shape)\n",
    "print('small_sample_ids shape:',small_sample_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8484690d-bbc1-4f80-880b-b5056d6476a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test/train split function on SMALL DEBUGGIN DATASET\n",
    "train_x, train_y, test_x, test_y = \\\n",
    "    emc.train_test_split_oversample(small_data, small_label, \n",
    "                                    oversample_type='ros', \n",
    "                                    split_ratio=0.8, \n",
    "                                    oversample_size=20,\n",
    "                                    seed=0)\n",
    "\n",
    "print(\"Number of active compounds in:\")\n",
    "print(\"Train Set = \", sum(train_y == 1))\n",
    "print(\"Test Set = \", sum(test_y == 1))\n",
    "\n",
    "print(\"Number of inactive compounds in:\")\n",
    "print(\"Train Set = \", sum(train_y == 0))\n",
    "print(\"Test Set = \", sum(test_y == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88801afb-078d-45d9-bf93-42668cce733d",
   "metadata": {},
   "source": [
    "### Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4558ef9e-0776-4a8a-946f-21173602f287",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configuration for both EMC and random sampling models\n",
    "config={\n",
    "    'emc_dir_path':'stroke_emc_res',\n",
    "    'rand_sampling_dir_path':'stroke_rand_sampling_res',\n",
    "    'n_sim':10,\n",
    "    'initial_train_ratio':0.05,    \n",
    "    # 'ros' OR 'smote' \n",
    "    'oversample_type':'smote', \n",
    "    'split_ratio':0.8,\n",
    "    # ratio in range [0.0,1.0] OR number (positive int) of samples to oversample\n",
    "    'oversample_size':0.5,\n",
    "    'log_freq':50\n",
    "}\n",
    "\n",
    "test_config={\n",
    "    'emc_dir_path':'stroke_emc_res',\n",
    "    'rand_sampling_dir_path':'stroke_rand_sampling_res',\n",
    "    'n_sim':3,\n",
    "    'initial_train_ratio':0.2,\n",
    "    # 'ros' OR 'smote' \n",
    "    'oversample_type':'smote', \n",
    "    'split_ratio':0.8,\n",
    "    # ratio in range [0.0,1.0] OR number (positive int) of samples to oversample\n",
    "    'oversample_size':0.2,\n",
    "    'log_freq':4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53e45ac-5505-4597-b625-1aba363d1540",
   "metadata": {},
   "source": [
    "### Set up results directory and logger  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907311ea-0e28-46ab-a54a-b1fe404c123f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make new directory to store results\n",
    "\n",
    "# emc sampling results directory\n",
    "emc_dir_path = emc.make_unique_file_name(config['emc_dir_path'])\n",
    "os.mkdir(emc_dir_path)\n",
    "\n",
    "# random sampling results directory\n",
    "rand_sampling_dir_path = emc.make_unique_file_name(config['rand_sampling_dir_path'])\n",
    "os.mkdir(rand_sampling_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbd54bf-3e88-448d-b3f0-0f60aaa00512",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up logger for emc sampling simulation\n",
    "logger_emc = logging.getLogger(__name__)\n",
    "logger_emc.setLevel(logging.INFO)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s %(message)s', datefmt='%Y-%m-%d %H:%M')\n",
    "file_handler = logging.FileHandler(f'{emc_dir_path}/emc.log')\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "logger_emc.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64850c9a-bc6e-48d1-b78e-ff83de59b1e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up logger for random sampling simulation\n",
    "logger_rand_sampler = logging.getLogger(__name__)\n",
    "logger_rand_sampler.setLevel(logging.INFO)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s %(message)s', datefmt='%Y-%m-%d %H:%M')\n",
    "file_handler = logging.FileHandler(f'{rand_sampling_dir_path}/rand_sampling.log')\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "logger_rand_sampler.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ca9dee",
   "metadata": {
    "id": "e3ca9dee"
   },
   "source": [
    "### Implementing Logistic Regression and Expected Model Change on Molecular Fingerprinting\n",
    "Logistic regression will be our base learner for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HUMJymQOJJGX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "HUMJymQOJJGX",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "87213270-97e8-429c-9d1c-f670bda652b5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EMC simulation on small test case data\n",
    "# emc.run_l_simulations_emc(small_data, small_label, sample_ids=small_sample_ids, **test_config)\n",
    "\n",
    "# EMC simulation on real data\n",
    "emc.run_l_simulations_emc(medical_data, is_stroke, sample_ids=sample_ids, **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411631a6-3e70-404e-97c1-17f287e53165",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Random Sampling simulation on small test case data\n",
    "# emc.run_n_simulations_random_sampling(small_data, small_label, **config)\n",
    "\n",
    "# Random Sampling simulation on real data\n",
    "emc.run_n_simulations_random_sampling(medical_data, is_stroke, **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860a7763-6692-4cbb-8cfc-ee2def3b4eca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load EMC results\n",
    "n_sim_accuracy_ls, n_sim_precision_ls, n_sim_recall_ls = [],[],[]\n",
    "\n",
    "for i in range(config['n_sim']):\n",
    "    n_sim_accuracy_ls.append(np.load(f\"{config['emc_dir_path']}/{i}_sim_emc_accuracy.npy\"))\n",
    "    n_sim_precision_ls.append(np.load(f\"{config['emc_dir_path']}/{i}_sim_emc_precision.npy\"))\n",
    "    n_sim_recall_ls.append(np.load(f\"{config['emc_dir_path']}/{i}_sim_emc_recall.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37971f8a-a842-4cac-b406-67dedb015ed3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Random Sampling results\n",
    "n_sim_accuracy_random_ls, n_sim_precision_random_ls, n_sim_recall_random_ls = [],[],[]\n",
    "\n",
    "for i in range(config['n_sim']):\n",
    "    n_sim_accuracy_random_ls.append(np.load(f\"{config['rand_sampling_dir_path']}/{i}_sim_rand_sample_accuracy.npy\"))\n",
    "    n_sim_precision_random_ls.append(np.load(f\"{config['rand_sampling_dir_path']}/{i}_sim_rand_sample_precision.npy\"))\n",
    "    n_sim_recall_random_ls.append(np.load(f\"{config['rand_sampling_dir_path']}/{i}_sim_rand_sample_recall.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc61ef34-6c6e-413f-874d-0ee8518a10d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_updates =  len(n_sim_accuracy_ls[0])\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "emc.plot_metrics(n_sim_accuracy_ls, n_updates, plot_separate_sim=False, color='red', label='emc query')\n",
    "emc.plot_metrics(n_sim_accuracy_random_ls, n_updates, plot_separate_sim=False, color='blue', label='random query')\n",
    "plt.title('Accuracy')\n",
    "plt.gca().yaxis.set_major_formatter(StrMethodFormatter('{x:,.2f}'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17c50ac-1154-4a87-96f5-5b9b6a362081",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "emc.plot_metrics(n_sim_precision_ls, n_updates, plot_separate_sim=False, color='red', label='emc query')\n",
    "emc.plot_metrics(n_sim_precision_random_ls, n_updates, plot_separate_sim=False, color='blue', label='random query')\n",
    "plt.title('Precision')\n",
    "plt.gca().yaxis.set_major_formatter(StrMethodFormatter('{x:,.2f}'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857b6d82-e41a-4602-b61b-4f5ae4a8dcc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "emc.plot_metrics(n_sim_recall_ls, n_updates, plot_separate_sim=False, color='red', label='emc query')\n",
    "emc.plot_metrics(n_sim_recall_random_ls, n_updates, plot_separate_sim=False, color='blue', label='random query')\n",
    "plt.title('Recall')\n",
    "plt.gca().yaxis.set_major_formatter(StrMethodFormatter('{x:,.2f}'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6b6b0b-2b0e-4347-a586-9e903fb9ee76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot for github\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "def metric_plotter(ax, x, emc_y, baseline_y, title):\n",
    "    ax.set_title(title)\n",
    "    ax.plot(x,emc_y,color='red', label='emc query')\n",
    "    ax.plot(x,baseline_y,color='blue',label='random query')\n",
    "    ax.legend()\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "\n",
    "n_updates =  len(n_sim_accuracy_ls[0])\n",
    "x = np.linspace(1, n_updates, n_updates)\n",
    "\n",
    "emc_avg_acc_arr = np.sum(n_sim_accuracy_ls,axis=0) / len(n_sim_accuracy_ls)\n",
    "emc_avg_prec_arr = np.sum(n_sim_precision_ls,axis=0) / len(n_sim_precision_ls)\n",
    "emc_avg_recall_arr = np.sum(n_sim_recall_ls,axis=0) / len(n_sim_recall_ls)\n",
    "\n",
    "rand_avg_acc_arr = np.sum(n_sim_accuracy_random_ls,axis=0) / len(n_sim_accuracy_random_ls)\n",
    "rand_avg_prec_arr = np.sum(n_sim_precision_random_ls,axis=0) / len(n_sim_precision_random_ls)\n",
    "rand_avg_recall_arr = np.sum(n_sim_recall_random_ls,axis=0) / len(n_sim_recall_random_ls)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3,1, figsize=(5,13))\n",
    "# plot\n",
    "metric_plotter(ax1, x, emc_avg_acc_arr, rand_avg_acc_arr, title=\"Accuracy\")\n",
    "metric_plotter(ax2, x, emc_avg_prec_arr, rand_avg_prec_arr, title=\"Precision\")\n",
    "metric_plotter(ax3, x, emc_avg_recall_arr, rand_avg_recall_arr, title=\"Recall\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1m7vLCLi8_ipyFsZTaW3luSGCkmHjIilj",
     "timestamp": 1681265672075
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
